{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bru5Yy6h6VW"
      },
      "source": [
        "# Contents\n",
        "\n",
        "In this notebook, we will see how we can download and use some of the classic pre-trained CNN architectures.\n",
        "\n",
        "We will use ResNet and VGG as examples. We will download and load both of these models.\n",
        "\n",
        "To show how to work with these models, we will use Cifar-10 dataset to run through the model(no training). The models will not give good results as the models aren't trained on CIFAR-10 and CIFAR-10 has a significantly lower number of classes, but it WILL show how to download and use the models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "O-ZY5gb9hir8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "from torchvision import datasets, models\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_d4PQO4jHwr",
        "outputId": "fd4224be-7ef6-4662-bb26-0699abf34412"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to CIFAR10/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170498071/170498071 [00:12<00:00, 13339911.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting CIFAR10/cifar-10-python.tar.gz to CIFAR10/\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "test_dataset = datasets.CIFAR10(\"CIFAR10/\", train=False, transform=transform, download=True)\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Rxo5nX9CphmO"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJtTz6QpjFtg"
      },
      "source": [
        "## VGG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ci3Al6iKiudH",
        "outputId": "d4eb9229-4bf3-45b6-c24e-ac39eed11079"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "vgg_model = models.vgg16(pretrained=True).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZK5uuTLHn3i9",
        "outputId": "86c9aa15-852f-4924-fdf9-8e65226a7310"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:49<00:00,  6.27it/s]\n"
          ]
        }
      ],
      "source": [
        "# Inference\n",
        "\n",
        "predicted_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "    for images, labels in tqdm(test_loader):\n",
        "\n",
        "        images = images.to(device)\n",
        "\n",
        "        batch_preds = vgg_model(images)\n",
        "        predicted_labels.extend(batch_preds.argmax(dim=-1).cpu().tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7GohbyVp0tm"
      },
      "source": [
        "## Resnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u259d71LonV9",
        "outputId": "daac0095-b055-4e05-cbe6-dd95ec948d63"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 195MB/s]\n"
          ]
        }
      ],
      "source": [
        "resnet_model = models.resnet18(pretrained=True).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tMBG9DVp-EK",
        "outputId": "37ce57f4-fed7-429f-eb73-1c1048b387f7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:19<00:00, 16.04it/s]\n"
          ]
        }
      ],
      "source": [
        "# Inference\n",
        "\n",
        "predicted_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "    for images, labels in tqdm(test_loader):\n",
        "\n",
        "        images = images.to(device)\n",
        "\n",
        "        batch_preds = resnet_model(images)\n",
        "        predicted_labels.extend(batch_preds.argmax(dim=-1).cpu().tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJMA0AT1qQ8m"
      },
      "source": [
        "For training, the process is the same as a custom model\n",
        "\n",
        "Write a training loop (without the \"no grad\"), define a loss and backprop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9H3Erj3ZqHrq"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
