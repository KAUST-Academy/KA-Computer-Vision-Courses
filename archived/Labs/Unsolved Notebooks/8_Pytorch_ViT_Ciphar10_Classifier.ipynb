{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Q_JRnxYlBS1r"},"outputs":[],"source":["from IPython.display import clear_output"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_Jqv5iAnBJNJ"},"outputs":[],"source":["%pip install torch\n","%pip install torchvision\n","%pip install matplotlib\n","\n","%pip install vit-pytorch\n","\n","clear_output()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"31RMbEJvjP8E"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision.transforms as transforms\n","import torchvision.datasets as datasets\n","from torch.utils.data import DataLoader\n","from vit_pytorch import SimpleViT\n","\n","from tqdm import tqdm"]},{"cell_type":"markdown","metadata":{"id":"_MsQqWtrB0vV"},"source":["# Contents:\n","\n","In this notebook, you are required to make a classifier for CIFAR10 dataset in pytorch using Vision Transformers(ViT).\n","\n","Make sure to show the performance of the model on the test(unseen) data after training\n","\n","Note: instead of using the full scale ViT (which is very large), you will use a library called [vit-pytorch](https://github.com/lucidrains/vit-pytorch) to build a smaller model based on vit architecture."]},{"cell_type":"markdown","metadata":{"id":"_MquRgv1DGlS"},"source":["## Loading the datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6250,"status":"ok","timestamp":1709844666987,"user":{"displayName":"Telha Bin Bilal","userId":"04147761314111353462"},"user_tz":-300},"id":"bx6kBXdwjUKL","outputId":"0f34dc6f-c442-4b6f-e45c-e3857ba53985"},"outputs":[],"source":["# Define your data transformations\n","transform = transforms.Compose([\n","    transforms.Resize(224),  # ViT models expect 224x224 images\n","    transforms.ToTensor(),\n","])\n","\n","# Load CIFAR-100 dataset\n","train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n","test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)"]},{"cell_type":"markdown","metadata":{"id":"5tky7DoDDPA7"},"source":["## Defining the model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w-EN1O_YjW3Y"},"outputs":[],"source":["# Define your model\n","# Fill in the missing params\n","\n","model = SimpleViT(\n","    image_size = ,\n","    patch_size = 32,\n","    num_classes = ,\n","    dim = ,\n","    depth = ,\n","    heads = ,\n","    mlp_dim = 2048\n",")"]},{"cell_type":"markdown","metadata":{},"source":["## Train the model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["## Show performance on test data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A2OAa2vnBjIA"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPMhboEGrA+vGo3DvHBclDJ","gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
