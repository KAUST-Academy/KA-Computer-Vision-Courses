{"cells":[{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1703244821352,"user":{"displayName":"Telha Bin Bilal","userId":"04147761314111353462"},"user_tz":-300},"id":"PbqMyExtTD5Q"},"outputs":[],"source":["from IPython.display import clear_output"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":37392,"status":"ok","timestamp":1703244862260,"user":{"displayName":"Telha Bin Bilal","userId":"04147761314111353462"},"user_tz":-300},"id":"sp95baEJTHLj"},"outputs":[],"source":["%pip install torch torchvision\n","%pip install numpy\n","%pip install scikit-learn\n","%pip install matplotlib\n","%pip install tqdm\n","\n","clear_output()"]},{"cell_type":"markdown","metadata":{"id":"-qchOMovTe1R"},"source":["## Contents\n","\n","In this notebook, you will use a pre-trained model to do similar image search/retrieval\n","\n","1. The idea is, we use a pre-trained image model to extract features / embeddings of a set of images\n","2. Then we use PCA to reduce the dimensions of these features (The searching will still work without PCA but dimensionality reduction helps with the speed of the model)\n","3. We will then pick a random image from the sample which will be our query image. We'll calculate the cosine similarity of the pca features of the query image with the pca features of all the images and pick the top images\n","\n","you will use Caltech 101 object categories dataset because of the high quality of images."]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":4957,"status":"ok","timestamp":1703243544740,"user":{"displayName":"Telha Bin Bilal","userId":"04147761314111353462"},"user_tz":-300},"id":"IKny9xmYzwYC"},"outputs":[],"source":["import random\n","\n","import numpy as np\n","\n","import torch\n","from torch.utils.data import DataLoader, Subset\n","\n","import torchvision\n","import torchvision.transforms as transforms\n","from torchvision import models\n","\n","from sklearn.decomposition import PCA\n","from sklearn.metrics.pairwise import cosine_similarity\n","\n","import matplotlib.pyplot as plt\n","\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1703243544740,"user":{"displayName":"Telha Bin Bilal","userId":"04147761314111353462"},"user_tz":-300},"id":"lddJRwLA0CNr"},"outputs":[],"source":["# For reproducable results. Can be skipped/commented.\n","torch.manual_seed(7)\n","random.seed(7)"]},{"cell_type":"markdown","metadata":{"id":"xb9_TaGO05a7"},"source":["## Downloading and Loading Images"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1061825,"status":"ok","timestamp":1703244606562,"user":{"displayName":"Telha Bin Bilal","userId":"04147761314111353462"},"user_tz":-300},"id":"zUzW2oUkKq5z","outputId":"90bcb099-93e0-4f04-a180-33612b666511"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading 101_Object_Categories for image notebooks\n","############################################################################################# 100.0%\n","Archive:  101_ObjectCategories.zip\n","replace __MACOSX/._caltech-101? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n","  inflating: __MACOSX/._caltech-101  \n","  inflating: caltech-101/101_ObjectCategories.tar.gz  \n","\n","  inflating: __MACOSX/caltech-101/._101_ObjectCategories.tar.gz  \n","  inflating: caltech-101/show_annotation.m  \n","  inflating: __MACOSX/caltech-101/._show_annotation.m  \n","  inflating: caltech-101/Annotations.tar  \n","  inflating: __MACOSX/caltech-101/._Annotations.tar  \n","101_ObjectCategories  101_ObjectCategories.zip\tcaltech-101  data  del\t__MACOSX  sample_data\n"]}],"source":["!echo \"Downloading 101_Object_Categories for image notebooks\"\n","\n","!curl -L -o 101_ObjectCategories.zip --progress-bar https://data.caltech.edu/records/mzrjq-6wc02/files/caltech-101.zip?download=1\n","!unzip 101_ObjectCategories.zip\n","!mv caltech-101/101_ObjectCategories.tar.gz ./101_ObjectCategories.tar.gz\n","!tar -xzf 101_ObjectCategories.tar.gz\n","!rm 101_ObjectCategories.tar.gz\n","!ls"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1703244606563,"user":{"displayName":"Telha Bin Bilal","userId":"04147761314111353462"},"user_tz":-300},"id":"v9cvDlwl4B51"},"outputs":[],"source":["batch_size = 64  # for batched. feature extraction\n","n_images = 1000  # num images to keep in the dataset.\n","n_pca_components = 300  # hyper param for number of top params to keep after PCA\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1703244606563,"user":{"displayName":"Telha Bin Bilal","userId":"04147761314111353462"},"user_tz":-300},"id":"qh-P8c4Q0-hW"},"outputs":[],"source":["transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","])\n","\n","# image_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)  # dataset can be replaced with CIFAR10\n","image_dataset = torchvision.datasets.ImageFolder(root='101_ObjectCategories', transform=transform)\n","random_indices = random.sample(range(len(image_dataset)), n_images)\n","images_subset = Subset(image_dataset, random_indices)\n","\n","image_loader = DataLoader(images_subset, batch_size, shuffle=False, num_workers=2)"]},{"cell_type":"markdown","metadata":{"id":"9cFUWWRK2mmE"},"source":["## Downloading and Loading model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2227,"status":"ok","timestamp":1703244608788,"user":{"displayName":"Telha Bin Bilal","userId":"04147761314111353462"},"user_tz":-300},"id":"DKkOvHZZl0Ut","outputId":"446bb928-4484-4d9c-d89d-394d4017cdc0"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]}],"source":["vgg16 = models.vgg16(pretrained=True)\n","vgg16.eval().to(device)\n","\n","# Make sure to use output of an ALMOST last layer of the model and not the final output.\n","# We want the vector representations of the images. The goal here is NOT classification"]},{"cell_type":"markdown","metadata":{"id":"Qj7qswfi8IVi"},"source":["## Extracting model features for all images\n","\n","Extract features of all the images"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"Iiz--Tt08PzK"},"source":["## Extracting PCA features\n","\n","Use PCA to reduce dimensionality of the features"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":1297,"status":"ok","timestamp":1703244617005,"user":{"displayName":"Telha Bin Bilal","userId":"04147761314111353462"},"user_tz":-300},"id":"zl8GAZTtmY8T"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"Xj7ytSQ18aBs"},"source":["## Let's get to image searching\n","\n","For this section:\n","\n","1. Pick a random image and it's corresponding PCA features\n","2. Show the picked image\n","3. calculate the cosine similarity of the chosen image's PCA features with PCA features of ALL other images\n","4. Find the indexes of top 5 most similar images(highest cosine similarity) and show those images. Hint: argsort\n","5. Visualize the images at these indexes. Are they similar?"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1703244618795,"user":{"displayName":"Telha Bin Bilal","userId":"04147761314111353462"},"user_tz":-300},"id":"5dAP4CS6E48G"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyP4yffgnd7GObKpgAH5QDTf","gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
